{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "ciq2m3ZM9g8E",
        "vyDm64o3JU1O"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Montar Drive"
      ],
      "metadata": {
        "id": "unB5XJQvGe9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WSGc5fgxGjA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdflib\n",
        "!pip install torch-geometric -q"
      ],
      "metadata": {
        "id": "l5k_gn1uIFru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semillas para que sea replicable"
      ],
      "metadata": {
        "id": "2karDwFFGRka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)                      # Semilla para random\n",
        "    np.random.seed(seed)                   # Semilla para NumPy\n",
        "    torch.manual_seed(seed)                # Semilla para PyTorch\n",
        "    torch.cuda.manual_seed(seed)           # Para CUDA (si usás GPU)\n",
        "    torch.cuda.manual_seed_all(seed)       # Por si hay múltiples GPUs\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)  # Elegí el número que quieras\n"
      ],
      "metadata": {
        "id": "GoqVqUceGTvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ruta archivo"
      ],
      "metadata": {
        "id": "EbV6K4li9aJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta al archivo .ttl que subiste\n",
        "ttl_path = \"/content/drive/MyDrive/Proyecto_Grafos_Conocimiento/grafoA_metadata.ttl\""
      ],
      "metadata": {
        "id": "RqxDAO0QG2u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construcción de Heterodata"
      ],
      "metadata": {
        "id": "ciq2m3ZM9g8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pnq_qDaTF2Pu"
      },
      "outputs": [],
      "source": [
        "# script_export_to_heterodata.py\n",
        "\n",
        "from rdflib import Graph, URIRef, RDF, Literal\n",
        "from collections import defaultdict\n",
        "from torch_geometric.data import HeteroData\n",
        "import torch\n",
        "from datetime import datetime\n",
        "\n",
        "# 1) Carga del grafo RDF\n",
        "#ttl_file = \"grafo_completo.ttl\"  # Ajusta la ruta a la propia\n",
        "ttl_file = ttl_path\n",
        "g = Graph()\n",
        "g.parse(ttl_file, format=\"turtle\")\n",
        "\n",
        "# 2) Helper de namespace\n",
        "NS = \"http://example.org/cdph/\"\n",
        "def uri(prop): return URIRef(NS + prop)\n",
        "\n",
        "# 3) Definición de clases RDF\n",
        "rdf_types = {\n",
        "    \"Product\":     uri(\"Product\"),\n",
        "    \"Brand\":       uri(\"Brand\"),\n",
        "    \"Company\":     uri(\"Company\"),\n",
        "    \"Category\":    uri(\"Category\"),\n",
        "    \"SubCategory\": uri(\"SubCategory\"),\n",
        "    \"Chemical\":    uri(\"Chemical\"),\n",
        "}\n",
        "\n",
        "# 4) Indexar nodos por tipo\n",
        "node_maps  = {nt: {} for nt in rdf_types}\n",
        "node_counts = {nt: 0 for nt in rdf_types}\n",
        "for subj, _, obj in g.triples((None, RDF.type, None)):\n",
        "    for ntype, cls in rdf_types.items():\n",
        "        if obj == cls and subj not in node_maps[ntype]:\n",
        "            node_maps[ntype][subj] = node_counts[ntype]\n",
        "            node_counts[ntype] += 1\n",
        "\n",
        "# 5) Pre-calcular edad y etiqueta para productos, y conteo de químicos\n",
        "prod_age   = {}\n",
        "prod_label = {}\n",
        "chem_counts = defaultdict(int)\n",
        "\n",
        "for prod_node in node_maps[\"Product\"]:\n",
        "    # Edad\n",
        "    init = g.value(prod_node, uri(\"hasInitialDateReported\"))\n",
        "    most = g.value(prod_node, uri(\"hasMostRecentDateReported\"))\n",
        "    age_days = 0\n",
        "    if isinstance(init, Literal) and isinstance(most, Literal):\n",
        "        try:\n",
        "            d0 = datetime.fromisoformat(str(init))\n",
        "            d1 = datetime.fromisoformat(str(most))\n",
        "            age_days = (d1 - d0).days\n",
        "        except:\n",
        "            pass\n",
        "    prod_age[prod_node] = age_days\n",
        "    # Etiqueta\n",
        "    prod_label[prod_node] = int(bool(g.value(prod_node, uri(\"hasDiscontinuedDate\"))))\n",
        "\n",
        "# Conteo de químicos por producto\n",
        "for s, _, o in g.triples((None, uri(\"productHasChemical\"), None)):\n",
        "    if s in node_maps[\"Product\"] and o in node_maps[\"Chemical\"]:\n",
        "        chem_counts[s] += 1\n",
        "\n",
        "# 6) Construir HeteroData\n",
        "data = HeteroData()\n",
        "\n",
        "# 7) Features y labels para Product\n",
        "prod_feats  = []\n",
        "prod_labels = []\n",
        "for prod_node, idx in sorted(node_maps[\"Product\"].items(), key=lambda x: x[1]):\n",
        "    feat = [\n",
        "        chem_counts.get(prod_node, 0),         # número de químicos\n",
        "        int(bool(g.value(prod_node, uri(\"productHasBrand\")))),\n",
        "        int(bool(g.value(prod_node, uri(\"productHasCategory\")))),\n",
        "        int(bool(g.value(prod_node, uri(\"productHasSubCategory\")))),\n",
        "        int(bool(g.value(prod_node, uri(\"productMadeByCompany\")))),\n",
        "    ]\n",
        "    prod_feats.append(feat)\n",
        "    prod_labels.append(prod_label[prod_node])\n",
        "\n",
        "data[\"Product\"].x = torch.tensor(prod_feats, dtype=torch.float)\n",
        "data[\"Product\"].y = torch.tensor(prod_labels, dtype=torch.long)\n",
        "\n",
        "# 8) Features para Chemical\n",
        "chem_feats = []\n",
        "for chem_node, idx in sorted(node_maps[\"Chemical\"].items(), key=lambda x: x[1]):\n",
        "    hv = 0\n",
        "    h_lit = g.value(chem_node, uri(\"hasHazardScore\"))\n",
        "    if isinstance(h_lit, Literal):\n",
        "        py = h_lit.toPython()\n",
        "        if isinstance(py, (int, float)):\n",
        "            hv = int(py)\n",
        "        else:\n",
        "            s = str(py)\n",
        "            hv = int(s) if s.isdigit() else 0\n",
        "    flags = [ # Me di cuenta de que son flags solo son indicaciones booleans despues de hacer la GNN, es decir, no estamos usando\n",
        "            # flags como tal, sino que son indicadores de si existen o no... lo cual como todos tiene hacen esta features inutiles XD.\n",
        "            # *Necesita cambio*\n",
        "        int(bool(g.value(chem_node, uri(\"AllergiesConcern\")))),\n",
        "        int(bool(g.value(chem_node, uri(\"CancerConcern\")))),\n",
        "        int(bool(g.value(chem_node, uri(\"DevelopReproductiveConcern\")))),\n",
        "        int(bool(g.value(chem_node, uri(\"UseRestrictionsConcern\")))),\n",
        "    ]\n",
        "    chem_feats.append([hv] + flags)\n",
        "\n",
        "data[\"Chemical\"].x = torch.tensor(chem_feats, dtype=torch.float)\n",
        "\n",
        "# 9) Features “agregadas” para Brand, Company, Category, SubCategory\n",
        "def build_hub_features(node_type, prop):\n",
        "    feats = []\n",
        "    for node, idx in sorted(node_maps[node_type].items(), key=lambda x: x[1]):\n",
        "        prods = [s for s, _, o in g.triples((None, uri(prop), node))]\n",
        "        n = len(prods)\n",
        "        if n > 0:\n",
        "            avg_age  = sum(prod_age[p] for p in prods) / n\n",
        "            avg_chem = sum(chem_counts.get(p,0) for p in prods) / n\n",
        "        else:\n",
        "            avg_age = avg_chem = 0.0\n",
        "        feats.append([n, avg_age, avg_chem])\n",
        "    return torch.tensor(feats, dtype=torch.float)\n",
        "\n",
        "data[\"Brand\"].x       = build_hub_features(\"Brand\",       \"productHasBrand\")\n",
        "data[\"Company\"].x     = build_hub_features(\"Company\",     \"productMadeByCompany\")\n",
        "data[\"Category\"].x    = build_hub_features(\"Category\",    \"productHasCategory\")\n",
        "data[\"SubCategory\"].x = build_hub_features(\"SubCategory\", \"productHasSubCategory\")\n",
        "\n",
        "# 10) Extraer aristas\n",
        "obj_props = {\n",
        "    (\"Product\", \"hasBrand\",       \"Brand\"):       \"productHasBrand\",\n",
        "    (\"Product\", \"hasCategory\",    \"Category\"):    \"productHasCategory\",\n",
        "    (\"Product\", \"hasSubCategory\", \"SubCategory\"): \"productHasSubCategory\",\n",
        "    (\"Product\", \"madeBy\",         \"Company\"):     \"productMadeByCompany\",\n",
        "    (\"Product\", \"hasChemical\",    \"Chemical\"):    \"containsChemical\",\n",
        "}\n",
        "\n",
        "for (src, rel, dst), prop in obj_props.items():\n",
        "    edges = []\n",
        "    for s, _, o in g.triples((None, uri(prop), None)):\n",
        "        if s in node_maps[src] and o in node_maps[dst]:\n",
        "            edges.append((node_maps[src][s], node_maps[dst][o]))\n",
        "    if edges:\n",
        "        data[(src, rel, dst)].edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# 11) Validar y mostrar resumen\n",
        "data.validate(raise_on_error=True)\n",
        "print(data)\n",
        "\n",
        "# 11) Guardar HeteroData en un archivo .pt dentro de Drive\n",
        "torch.save(data, \"/content/drive/MyDrive/Proyecto_Grafos_Conocimiento/hetero_data.pt\")\n",
        "print(\"HeteroData serializado en '/content/drive/MyDrive/Proyecto_Grafos_Conocimiento/hetero_data.pt'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING EMBEDDINGS"
      ],
      "metadata": {
        "id": "vyDm64o3JU1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.data.storage import NodeStorage, EdgeStorage, BaseStorage\n",
        "\n",
        "# Permitir todas las clases necesarias para cargar el HeteroData\n",
        "with torch.serialization.safe_globals({\n",
        "    NodeStorage: NodeStorage,\n",
        "    EdgeStorage: EdgeStorage,\n",
        "    BaseStorage: BaseStorage\n",
        "}):\n",
        "    data = torch.load(\"/content/drive/MyDrive/Proyecto_Grafos_Conocimiento/hetero_data.pt\")\n",
        "\n",
        "# Mostrar resumen del grafo cargado\n",
        "print(data)\n",
        "print(\"Tipos de nodos:\", data.node_types)\n",
        "print(\"Tipos de aristas:\", data.edge_types)\n"
      ],
      "metadata": {
        "id": "3kX2wX2eJl8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WITeyZ21KRyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edge_keys = list(data.edge_index_dict.keys())  # Copia para evitar errores al iterar\n",
        "for (src, rel, dst) in edge_keys:\n",
        "    inv_rel = rel + \"_rev\"\n",
        "    if (dst, inv_rel, src) not in data.edge_index_dict:\n",
        "        data[(dst, inv_rel, src)].edge_index = data[(src, rel, dst)].edge_index.flip(0)"
      ],
      "metadata": {
        "id": "lcXVuAFqKV1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import MetaPath2Vec\n",
        "\n",
        "# 🔁 Paso 1: Definir un solo metacaminos válido\n",
        "metapath = [\n",
        "    ('Product', 'hasBrand', 'Brand'),\n",
        "    ('Brand', 'hasBrand_rev', 'Product')\n",
        "]\n",
        "\n",
        "# ⚙️ Paso 2: Crear el modelo con argumentos en orden correcto\n",
        "model = MetaPath2Vec(\n",
        "    data.edge_index_dict,  # edge_index_dict: diccionario de aristas\n",
        "    128,                   # embedding_dim: tamaño de embedding\n",
        "    metapath,              # metapath: lista de relaciones conectadas\n",
        "    4,                     # walk_length: largo de caminata\n",
        "    2                      # context_size: tamaño de ventana\n",
        ")"
      ],
      "metadata": {
        "id": "Z06-eSRVLsak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "# Cargar generador de muestras para entrenamiento\n",
        "loader = model.loader(batch_size=128, shuffle=True, num_workers=0)\n",
        "\n",
        "# Usamos Adam ya que los embeddings son densos\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "Bp1ZuMKtPUlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for pos_rw, neg_rw in loader:\n",
        "        pos_rw, neg_rw = pos_rw.to(device), neg_rw.to(device)\n",
        "        loss = model.loss(pos_rw, neg_rw)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)"
      ],
      "metadata": {
        "id": "WQTruKsEPWjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "\n",
        "for epoch in range(1, 35):  # Aumente si quiere más calidad\n",
        "    loss = train()\n",
        "    train_losses.append(loss)\n",
        "    print(f\"Época {epoch:02d} | Pérdida: {loss:.4f}\")"
      ],
      "metadata": {
        "id": "hmHp9KPGPZCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(train_losses, marker='o', color='blue', label=\"Pérdida de entrenamiento\")\n",
        "plt.title(\"Curva de pérdida durante el entrenamiento\")\n",
        "plt.xlabel(\"Época\")\n",
        "plt.ylabel(\"Pérdida\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uOY5aXJQPbOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta donde guardar el modelo entrenado\n",
        "ruta_modelo = \"/content/drive/MyDrive/Proyecto_Grafos_Conocimiento/metapath2vec_model.pt\"\n",
        "\n",
        "# Guardar modelo completo\n",
        "torch.save(model.state_dict(), ruta_modelo)\n",
        "print(f\"📦 Modelo guardado en: {ruta_modelo}\")"
      ],
      "metadata": {
        "id": "liGrYBROPt2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    product_emb = model('Product').cpu().numpy()  # tensor → numpy array"
      ],
      "metadata": {
        "id": "hWPJa9EoQHDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# Normalizar cada embedding al vector unitario\n",
        "product_emb_normalized = normalize(product_emb)\n",
        "\n",
        "# Luego aplicás t-SNE, PCA o UMAP sobre esto"
      ],
      "metadata": {
        "id": "EeA_LfPLUi2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Opción A: Visualizar con PCA (Análisis de Componentes Principales"
      ],
      "metadata": {
        "id": "W-zgwvlrQJa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "emb_pca = pca.fit_transform(product_emb)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(emb_pca[:,0], emb_pca[:,1], s=5, alpha=0.7)\n",
        "plt.title(\"Embeddings de Productos (PCA)\")\n",
        "plt.xlabel(\"Componente 1\")\n",
        "plt.ylabel(\"Componente 2\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pOwZz81FQIqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Transformar a PCA\n",
        "emb_pca = PCA(n_components=2).fit_transform(product_emb)\n",
        "\n",
        "# Crear DataFrame con etiquetas opcionales\n",
        "df = pd.DataFrame({\n",
        "    \"x\": emb_pca[:, 0],\n",
        "    \"y\": emb_pca[:, 1],\n",
        "    \"id\": [f\"Producto_{i}\" for i in range(len(emb_pca))]  # etiquetas opcionales\n",
        "})\n",
        "\n",
        "# Gráfico interactivo\n",
        "fig = px.scatter(df, x=\"x\", y=\"y\", text=\"id\",\n",
        "                 title=\"Visualización interactiva de embeddings (PCA)\",\n",
        "                 labels={\"x\": \"Componente 1\", \"y\": \"Componente 2\"})\n",
        "\n",
        "fig.update_traces(marker=dict(size=4), textposition='top center')\n",
        "fig.update_layout(height=600, width=600)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Ewhv_zuVaF_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D  # para gráfico 3D\n",
        "\n",
        "# Aplicar PCA a 3 componentes\n",
        "pca = PCA(n_components=3)\n",
        "emb_pca_3d = pca.fit_transform(product_emb)\n",
        "\n",
        "# Visualizar en 3D\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.scatter(\n",
        "    emb_pca_3d[:,0],\n",
        "    emb_pca_3d[:,1],\n",
        "    emb_pca_3d[:,2],\n",
        "    s=5,\n",
        "    alpha=0.7,\n",
        "    color='steelblue'\n",
        ")\n",
        "\n",
        "ax.set_title(\"Embeddings de Productos (PCA 3D)\")\n",
        "ax.set_xlabel(\"PC 1\")\n",
        "ax.set_ylabel(\"PC 2\")\n",
        "ax.set_zlabel(\"PC 3\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bf7V6ZmWQUMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explained = pca.explained_variance_ratio_\n",
        "print(f\"📊 Varianza explicada por cada componente: {explained}\")\n",
        "print(f\"📈 Varianza total explicada (3 componentes): {explained.sum():.2%}\")"
      ],
      "metadata": {
        "id": "go-c-HszQd8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Asegúrate de tener los embeddings en esta variable (sin gradientes)\n",
        "# product_emb = model('Product') si no lo has hecho antes\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    product_emb = model('Product').cpu().numpy()\n",
        "\n",
        "# Aplicar t-SNE (puedes ajustar `perplexity` y `n_iter` si quieres mejorar resultados)\n",
        "tsne = TSNE(n_components=2, perplexity=30, n_iter=350, random_state=42)\n",
        "product_emb_2d = tsne.fit_transform(product_emb)\n",
        "\n",
        "# Graficar\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(product_emb_2d[:, 0], product_emb_2d[:, 1], s=5, alpha=0.6)\n",
        "plt.title(\"📌 Visualización de Embeddings de Productos (t-SNE 2D)\")\n",
        "plt.xlabel(\"Componente 1\")\n",
        "plt.ylabel(\"Componente 2\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pSEE8ApKQni1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "norms = np.linalg.norm(product_emb, axis=1)\n",
        "print(f\"🔍 Máxima norma: {norms.max():.4f}, Mínima norma: {norms.min():.4f}\")"
      ],
      "metadata": {
        "id": "JqlRlQmsUWCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norms = product_emb.norm(dim=1)\n",
        "print(f\"Máxima norma: {norms.max():.4f}, Mínima norma: {norms.min():.4f}\")\n"
      ],
      "metadata": {
        "id": "FbhV_x8VUDyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "metadata": {
        "id": "SmGETImRSIgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap.umap_ as umap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Supongamos que product_emb es el tensor de embeddings de productos\n",
        "# Asegúrate de pasarlo como NumPy\n",
        "product_emb_np = product_emb.cpu().detach().numpy()\n",
        "\n",
        "# UMAP en 2D\n",
        "umap_2d = umap.UMAP(n_components=2, random_state=42)\n",
        "emb_umap = umap_2d.fit_transform(product_emb_np)\n",
        "\n",
        "# Visualización\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(emb_umap[:, 0], emb_umap[:, 1], s=2, alpha=0.6)\n",
        "plt.title(\"Embeddings de Productos (UMAP 2D)\", fontsize=14)\n",
        "plt.xlabel(\"UMAP 1\")\n",
        "plt.ylabel(\"UMAP 2\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6cSi0_-5SLvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Opcion con metacaminos diferentes y relaciones inversas para captar más contexto y simetras, además de saltos más largos"
      ],
      "metadata": {
        "id": "MVI_lzT9-FPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdflib\n",
        "!pip install torch-geometric -q"
      ],
      "metadata": {
        "id": "EaiVGCoeTevH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.data.storage import NodeStorage, EdgeStorage, BaseStorage\n",
        "\n",
        "# Permitir todas las clases necesarias para cargar el HeteroData\n",
        "with torch.serialization.safe_globals({\n",
        "    NodeStorage: NodeStorage,\n",
        "    EdgeStorage: EdgeStorage,\n",
        "    BaseStorage: BaseStorage\n",
        "}):\n",
        "    data = torch.load(\"/content/drive/MyDrive/Proyecto_Grafos_Conocimiento/hetero_data.pt\")\n",
        "\n",
        "# Mostrar resumen del grafo cargado\n",
        "print(data)\n",
        "print(\"Tipos de nodos:\", data.node_types)\n",
        "print(\"Tipos de aristas:\", data.edge_types)"
      ],
      "metadata": {
        "id": "7CRBKzoQTtrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (src, rel, dst), edge in data.edge_index_dict.items():\n",
        "    if src == 'Product':\n",
        "        print(f\"{rel} → {dst}: {edge.size(1)} conexiones\")\n"
      ],
      "metadata": {
        "id": "lDZHlX0_CLub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.edge_index_dict.keys())\n"
      ],
      "metadata": {
        "id": "I9JgmjuQA385"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.edge_index_dict.keys())\n"
      ],
      "metadata": {
        "id": "erMchFYOBEMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Generar relaciones inversas para cada edge\n",
        "edge_keys = list(data.edge_index_dict.keys())\n",
        "for (src, rel, dst) in edge_keys:\n",
        "    inv_rel = rel + \"_rev\"\n",
        "    if (dst, inv_rel, src) not in data.edge_index_dict:\n",
        "        data[(dst, inv_rel, src)].edge_index = data[(src, rel, dst)].edge_index.flip(0)\n",
        "\n",
        "# 2. Importar librerías necesarias\n",
        "from torch_geometric.nn import MetaPath2Vec\n",
        "\n",
        "# 3. Definir todos los metacaminos válidos basados en tu grafo\n",
        "metapath = [\n",
        "    ('Product', 'hasBrand', 'Brand'),\n",
        "    ('Brand', 'hasBrand_rev', 'Product'),\n",
        "\n",
        "    ('Product', 'hasCategory', 'Category'),\n",
        "    ('Category', 'hasCategory_rev', 'Product'),\n",
        "\n",
        "    ('Product', 'hasSubCategory', 'SubCategory'),\n",
        "    ('SubCategory', 'hasSubCategory_rev', 'Product'),\n",
        "\n",
        "    ('Product', 'madeBy', 'Company'),\n",
        "    ('Company', 'madeBy_rev', 'Product'),\n",
        "]\n",
        "\n",
        "# 4. Crear el modelo con parámetros ajustables\n",
        "\n",
        "model = MetaPath2Vec(\n",
        "    data.edge_index_dict,\n",
        "    embedding_dim=128,     # Buena representación\n",
        "    metapath=metapath,\n",
        "    walk_length=7,         # Caminata razonable\n",
        "    context_size=3         # Algo más de contexto\n",
        ")\n",
        "# 5. Enviar a GPU si está disponible\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "# 6. Cargar generador de muestras\n",
        "loader = model.loader(batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "# 7. Definir optimizador y función de entrenamiento\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for pos_rw, neg_rw in loader:\n",
        "        pos_rw, neg_rw = pos_rw.to(device), neg_rw.to(device)\n",
        "        loss = model.loss(pos_rw, neg_rw)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# 8. Entrenar por varias épocas\n",
        "train_losses = []\n",
        "for epoch in range(1,201):\n",
        "    loss = train()\n",
        "    train_losses.append(loss)\n",
        "    print(f\"Época {epoch:02d} | Pérdida: {loss:.4f}\")"
      ],
      "metadata": {
        "id": "RGA_hQo5S2w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guardar modelo con fecha y hora para poder cargarlo"
      ],
      "metadata": {
        "id": "1p4mS3iOFso-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import torch\n",
        "\n",
        "# Obtener fecha y hora actual como string\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Se define la ruta con timestamp incluido para guardarlo\n",
        "ruta_modelo = f\"/content/drive/MyDrive/Proyecto_Grafos_Conocimiento/metapath2vec_model_{timestamp}.pt\"\n",
        "\n",
        "# Guardar modelo con la fecha para saber cual es en particular\n",
        "torch.save(model.state_dict(), ruta_modelo)\n",
        "print(f\"💾 Modelo guardado en: {ruta_modelo}\")\n"
      ],
      "metadata": {
        "id": "lF_8rpwiS8A5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graficar la pérdida"
      ],
      "metadata": {
        "id": "p0c-aAecF1jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_losses, marker='*', color='red', label=\"Pérdida de entrenamiento\")\n",
        "plt.title(\"Curva de pérdida durante el entrenamiento\")\n",
        "plt.xlabel(\"Época\")\n",
        "plt.ylabel(\"Pérdida\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nzJtDOdNG6Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descendío bien, por lo que debería haber aprendido relativamente bien"
      ],
      "metadata": {
        "id": "eIZSvQfyHMRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly"
      ],
      "metadata": {
        "id": "VElX-so-IapX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos embeddings"
      ],
      "metadata": {
        "id": "kcsr8u9lJIEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdflib import Graph, RDF, URIRef\n",
        "g = Graph()\n",
        "g.parse(\"/content/drive/MyDrive/Proyecto_Grafos_Conocimiento/grafoA_metadata.ttl\", format=\"turtle\")"
      ],
      "metadata": {
        "id": "lpDsBd5MSSsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NS = \"http://example.org/cdph/\"\n",
        "def uri(prop): return URIRef(NS + prop)"
      ],
      "metadata": {
        "id": "-0Qgm_W7SV_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "name_prop = uri(\"hasProductName\")\n",
        "products = []\n",
        "\n",
        "for subj in g.subjects(RDF.type, uri(\"Product\")):\n",
        "    label = g.value(subj, name_prop)\n",
        "    name = str(label) if label else subj.split(\"/\")[-1]\n",
        "    products.append((str(subj), name))\n",
        "\n",
        "df_products = pd.DataFrame(products, columns=[\"uri\", \"label\"])\n",
        "df_products = df_products.sort_values(by=\"uri\").reset_index(drop=True)"
      ],
      "metadata": {
        "id": "HQ7S4NYfSYyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "name_prop = uri(\"hasProductName\")\n",
        "products = []\n",
        "\n",
        "for subj in g.subjects(RDF.type, uri(\"Product\")):\n",
        "    label = g.value(subj, name_prop)\n",
        "    name = str(label) if label else subj.split(\"/\")[-1]\n",
        "    products.append((str(subj), name))\n",
        "\n",
        "df_products = pd.DataFrame(products, columns=[\"uri\", \"label\"])\n",
        "df_products = df_products.sort_values(by=\"uri\").reset_index(drop=True)"
      ],
      "metadata": {
        "id": "qoEpveJsScwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ejemplos de mapeo URI ↔ Nombre de producto:\\n\")\n",
        "for i in range(10):  # Puedes aumentar el rango si quieres más\n",
        "    print(f\"{i}. {df_products.iloc[i]['uri']} → {df_products.iloc[i]['label']}\")"
      ],
      "metadata": {
        "id": "sxk2koTpSpHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecciona el URI del producto que quieres revisar\n",
        "prod_uri = URIRef(\"http://example.org/cdph/Product-18\")\n",
        "\n",
        "# Busca todas las propiedades asociadas a ese producto\n",
        "for p, o in g.predicate_objects(subject=prod_uri):\n",
        "    print(f\"{p} -> {o}\")"
      ],
      "metadata": {
        "id": "KN3Yw1vGTViP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    product_emb = model('Product').cpu().numpy()"
      ],
      "metadata": {
        "id": "bqMxj24HUohI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "product_emb_normalized = normalize(product_emb, norm='l2')"
      ],
      "metadata": {
        "id": "qXD0BpJvU7Wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "product_2d = pca.fit_transform(product_emb_normalized)"
      ],
      "metadata": {
        "id": "vYW2UroBU9fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# DataFrame con los componentes principales\n",
        "df_plot = pd.DataFrame(product_2d, columns=[\"PC1\", \"PC2\"])\n",
        "\n",
        "# Agregamos URI y nombre\n",
        "df_plot[\"uri\"] = df_products[\"uri\"]\n",
        "df_plot[\"Nombre\"] = df_products[\"label\"]\n",
        "\n",
        "# Combinamos URI + Nombre\n",
        "df_plot[\"uri_nombre\"] = df_plot[\"uri\"] + \" → \" + df_plot[\"Nombre\"]\n",
        "\n",
        "# Gráfico interactivo\n",
        "fig = px.scatter(\n",
        "    df_plot,\n",
        "    x=\"PC1\", y=\"PC2\",\n",
        "    hover_name=\"uri_nombre\",  # Se muestra URI + nombre al pasar el mouse\n",
        "    title=\"Visualización PCA de embeddings de productos\"\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "wWjFOjGpVaMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# 1. PCA a 3 componentes\n",
        "pca_3d = PCA(n_components=3)\n",
        "product_3d = pca_3d.fit_transform(product_emb_normalized)\n",
        "\n",
        "# 2. Crear DataFrame con PC1, PC2 y PC3\n",
        "df_plot3d = pd.DataFrame(product_3d, columns=[\"PC1\", \"PC2\", \"PC3\"])\n",
        "\n",
        "# 3. Añadir URI y nombre del producto\n",
        "df_plot3d[\"uri\"] = df_products[\"uri\"]\n",
        "df_plot3d[\"Nombre\"] = df_products[\"label\"]\n",
        "df_plot3d[\"uri_nombre\"] = df_plot3d[\"uri\"] + \" → \" + df_plot3d[\"Nombre\"]\n",
        "\n",
        "# 4. Gráfico 3D interactivo\n",
        "fig = px.scatter_3d(\n",
        "    df_plot3d,\n",
        "    x=\"PC1\", y=\"PC2\", z=\"PC3\",\n",
        "    hover_name=\"uri_nombre\",\n",
        "    title=\"Visualización PCA 3D de embeddings de productos\"\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "WUc5pOmyVuzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener categoría de cada producto\n",
        "category_map = {}\n",
        "for s, p, o in g.triples((None, URIRef(\"http://example.org/cdph/productHasCategory\"), None)):\n",
        "    category_map[str(s)] = str(o).split(\"/\")[-1]  # Extrae solo el número final de la categoría\n",
        "\n",
        "# Crear una columna de categoría\n",
        "df_plot3d[\"Categoria\"] = df_plot3d[\"uri\"].map(category_map)"
      ],
      "metadata": {
        "id": "rWPgKJHjWByf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.scatter(\n",
        "    df_plot3d,\n",
        "    x=\"PC1\", y=\"PC2\",\n",
        "    hover_name=\"uri_nombre\",\n",
        "    color=\"Categoria\",  # 💡 Sigue coloreando por categoría\n",
        "    title=\"Visualización PCA 2D de productos por categoría\"\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "cXSmvFZlXzAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter_3d(\n",
        "    df_plot3d,\n",
        "    x=\"PC1\", y=\"PC2\", z=\"PC3\",\n",
        "    hover_name=\"uri_nombre\",\n",
        "    color=\"Categoria\",  # 💡 Aquí se colorea por categoría\n",
        "    title=\"Visualización PCA 3D de productos por categoría\"\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "7KQHDMeqWEle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "metadata": {
        "id": "YGtN1ijtY7c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Se aplicó reducción de dimensionalidad en dos partes: primero con PCA a 50 componentes principales para capturar las estructuras globales más relevantes y eliminar parte del ruido, y luego con t-SNE para proyectar el espacio que da la proyección en 2D/3D, para poder explorar las relaciones locales entre productos cosméticos."
      ],
      "metadata": {
        "id": "x2Y12GkLeR-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import umap.umap_ as umap\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# DataFrame base con URI y Nombre del producto\n",
        "df_base = pd.DataFrame({\n",
        "    \"uri\": df_products[\"uri\"],\n",
        "    \"uri_nombre\": df_products[\"uri\"] + \" → \" + df_products[\"label\"],\n",
        "    \"Categoria\": df_products[\"uri\"].map(category_map)\n",
        "})\n",
        "\n",
        "# PCA para reducción previa (usado luego en t-SNE acelerado)\n",
        "pca = PCA(n_components=50)\n",
        "X_pca = pca.fit_transform(product_emb_normalized)\n",
        "\n",
        "### 1. t-SNE 2D\n",
        "tsne_2d = TSNE(n_components=2, perplexity=30, n_iter=250)\n",
        "X_tsne_2d = tsne_2d.fit_transform(X_pca)\n",
        "\n",
        "fig1 = px.scatter(\n",
        "    x=X_tsne_2d[:, 0], y=X_tsne_2d[:, 1],\n",
        "    color=df_base[\"Categoria\"],\n",
        "    hover_name=df_base[\"uri_nombre\"],\n",
        "    title=\"t-SNE 2D con PCA previo\"\n",
        ")\n",
        "fig1.show()\n",
        "\n",
        "### 2. t-SNE 3D\n",
        "tsne_3d = TSNE(n_components=3, perplexity=30, n_iter=250)\n",
        "X_tsne_3d = tsne_3d.fit_transform(X_pca)\n",
        "\n",
        "fig2 = px.scatter_3d(\n",
        "    x=X_tsne_3d[:, 0], y=X_tsne_3d[:, 1], z=X_tsne_3d[:, 2],\n",
        "    color=df_base[\"Categoria\"],\n",
        "    hover_name=df_base[\"uri_nombre\"],\n",
        "    title=\"t-SNE 3D con PCA previo\"\n",
        ")\n",
        "fig2.show()\n",
        "\n",
        "### 3. UMAP 2D\n",
        "umap_2d = umap.UMAP(n_components=2)\n",
        "X_umap_2d = umap_2d.fit_transform(product_emb_normalized)\n",
        "\n",
        "fig3 = px.scatter(\n",
        "    x=X_umap_2d[:, 0], y=X_umap_2d[:, 1],\n",
        "    color=df_base[\"Categoria\"],\n",
        "    hover_name=df_base[\"uri_nombre\"],\n",
        "    title=\"UMAP 2D\"\n",
        ")\n",
        "fig3.show()\n",
        "\n",
        "### 4. UMAP 3D\n",
        "umap_3d = umap.UMAP(n_components=3)\n",
        "X_umap_3d = umap_3d.fit_transform(product_emb_normalized)\n",
        "\n",
        "fig4 = px.scatter_3d(\n",
        "    x=X_umap_3d[:, 0], y=X_umap_3d[:, 1], z=X_umap_3d[:, 2],\n",
        "    color=df_base[\"Categoria\"],\n",
        "    hover_name=df_base[\"uri_nombre\"],\n",
        "    title=\"UMAP 3D\"\n",
        ")\n",
        "fig4.show()"
      ],
      "metadata": {
        "id": "mRsXwYRpZbgB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}